{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision – Litghning & Color Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprender el papel que juegan las condiciones de iluminación en el desarrollo de un sistema de visión por computadora. Y analizaremos los cuatro espacios de color primarios que encontraremos en la visión artificial: RGB, HSV, L * a * b * y escala de grises (que técnicamente no es un espacio de color, pero se usa en muchas aplicaciones de visión artificial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El campo de la visión por ordenador se está expandiendo y evolucionando rápidamente. Todos los días estamos viendo nuevos avances en el campo que una vez pensamos que eran imposibles. Estamos viendo que el aprendizaje profundo clasifica las imágenes con una precisión asombrosamente alta. Pequeñas computadoras pequeñas, como la Raspberry Pi, pueden usarse para construir sistemas de vigilancia. Y la industria está viendo cada vez más aplicaciones comerciales de visión computacional puestas en el mercado. Y mientras el campo está creciendo, cambiando y evolucionando, pero hay que decir que hay una constante absoluta que nunca cambiará: cada algoritmo, aplicación y sistema de visión de computadora jamás desarrollado y que se desarrollará dependerá de la calidad de las imágenes ingresadas a el sistema. Sin duda, podremos hacer que nuestros sistemas sean más robustos en relación con las condiciones de iluminación deficientes, pero nunca podremos superar una imagen capturada en condiciones inferiores. **La iluminación puede significar la diferencia entre el éxito y el fracaso del algoritmo de visión de su computadora.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, sus condiciones de iluminación deben tener tres objetivos principales. Vamos a revisarlos a continuación. \n",
    "\n",
    "- **Alto contraste:** Tenemos que maximizar el contraste entre las regiones de interés en nuestras imagenes (es decir, los \"objetos\" que deseamos detectar, extraer, describir, clasificar, manipular, etc. debemos tener un contraste suficientemente alto del resto de la imagen para que sean fácilmente detectables).\n",
    "\n",
    "\n",
    "- **Generalizable:** Las condiciones de iluminación deben ser lo suficientemente consistentes como para que funcionen bien de un \"objeto\" al siguiente. Si nuestro objetivo es identificar varias troncos por ejemplo en Idom, nuestras condiciones de iluminación deberían ser lo suficientemente generalizadas para facilitar la identificación del tronco, ya sea que estemos examinando un tronco de otro tipo, con mas cantidad de troncos alrededor o mas alejado obteniendo mas panorama del alrededor del objeto.\n",
    "\n",
    "\n",
    "- **Estable:** Tenemos que tener condiciones de iluminación estables, consistentes y repetibles. Pienso que es el santo grial del desarrollo de aplicaciones de visión artificial. Sin embargo, a menudo es difícil (si no imposible) garantizarlo, esto es especialmente cierto si estamos desarrollando algoritmos de visión artificial diseñados para funcionar en condiciones de iluminación exterior. A medida que cambia la hora del día, las nubes pasan sobre el sol y comienza a llover, nuestras condiciones de iluminación obviamente cambiarán esto es muy importante para el proyecto de Idom.\n",
    "\n",
    "**CONSEJO. Tenemos que esforzarnos lo más posible por obtener las condiciones de iluminación ideales incluso antes de escribir una sola línea de código. Creo que es sustancialmente más beneficioso (y más fácil) controlar (o al menos reconocer) nuestras condiciones de iluminación que escribir un código para compensar una iluminación inferior.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters import threshold_local\n",
    "\n",
    "image = cv2.imread(\"C:/Users/algonzalez/source/repos/Computer_Vision/1_Basics_of_Computer_Vision/images/IMG_1009.JPG\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir un color en el modelo de color RGB, todo lo que tenemos que hacer es definir la cantidad de rojo, verde y azul que contiene un solo píxel. Cada canal rojo, verde y azul puede tener valores definidos en el rango [0, 255] (para un total de 256 \"sombras\"), donde 0 indica que no hay representación y 255 demuestra la representación completa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que un color RGB se define como una tupla de 3 valores, con cada valor en el rango [0, 255], podemos pensar en el cubo que contiene 256 x 256 x 256 = 16,777,216 colores posibles, dependiendo de cuánto rojo, verde , y azul colocamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop sobre cada uno de los canales\n",
    "for (name, chan) in zip((\"B\", \"G\", \"R\"), cv2.split(image)):\n",
    "    cv2.imshow(name, chan)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El espacio de color HSV transforma el espacio de color RGB, remodelando como un cilindro en lugar de un cubo: \n",
    "\n",
    "Como vimos en la sección RGB, el \"blanco\" o \"luminosidad\" de un color es una combinación aditiva de cada componente Rojo, Verde y Azul. Pero ahora, en el espacio de color HSV, la luminosidad tiene su propia dimensión separada.\n",
    "\n",
    "- **Tono:** cual color \"puro\" estamos examinando. Por ejemplo, todas las sombras y tonos del color \"rojo\" tendrán el mismo tono.\n",
    "\n",
    "- **Saturación:** cómo \"blanco\" es el color. Un color totalmente saturado sería \"puro\", como en \"rojo puro\". Y un color con saturación cero sería blanco puro. \n",
    "\n",
    "- **Valor:** El valor nos permite controlar la luminosidad de nuestro color. Un valor de cero indicaría negro puro, mientras que aumentar el valor produciría colores más claros. Es importante tener en cuenta que las diferentes bibliotecas de visión artificial usarán diferentes rangos para representar cada uno de los componentes de Tono, Saturación y Valor.\n",
    "\n",
    "Si bien el espacio de color RGB es fácil de entender, no es intuitivo al definir los tonos exactos de un color o al especificar un rango de colores en particular. Por otro lado, el espacio de color HSV es más intuitivo, pero no hace el mejor trabajo al representar cómo los humanos ven e interpretan los colores en las imágenes. Ahí es donde entra en juego el espacio de color L * a * b *, su objetivo es imitar la metodología en la que los humanos ven e interpretan el color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"HSV\", hsv)\n",
    "\n",
    "# loop sobre cada uno de los canales de HSV\n",
    "for (name, chan) in zip((\"H\", \"S\", \"V\"), cv2.split(hsv)):\n",
    "    cv2.imshow(name, chan)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L*a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Canal L:** La “luminosidad” del píxel. Este valor sube y baja del eje vertical, blanco a negro, con grises neutros en el centro del eje. \n",
    "- **a-channel:** se origina en el centro del canal L y define el verde puro en un extremo del espectro y el rojo puro en el otro. canal \n",
    "- **b:** También se origina en el centro del canal L, pero es perpendicular al canal a. El canal B define azul puro en uno de los espectros y amarillo puro en el otro.\n",
    "\n",
    "Similar a nuestro ejemplo de HSV, tenemos el canal L* que se dedica a mostrar qué tan claro es un píxel dado. El a * y el b * luego determinan el tono y el color del píxel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow(\"L*a*b*\", lab)\n",
    "\n",
    "# loop sobre cada uno de los canales de \"L*a*b*\n",
    "for (name, chan) in zip((\"L*\", \"a*\", \"b*\"), cv2.split(lab)):\n",
    "    cv2.imshow(name, chan)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes en escala de grises son imágenes de un solo canal con valores de píxeles en el rango [0, 255] (es decir, 256 valores únicos). No confundir con imágenes en blanco y negro que únicamente tienen un rango de valores de 0 o 255. Este espacio de color nos permite conservar la memoria y ser más eficientes computacionalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Grayscale\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and merge colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "(B, G, R) = cv2.split(image)\n",
    "\n",
    "# Mostrar cada cana de manera individual\n",
    "cv2.imshow(\"Red\", R)\n",
    "cv2.imshow(\"Green\", G)\n",
    "cv2.imshow(\"Blue\", B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Merge de los canales de nuevo\n",
    "merged = cv2.merge([B, G, R])\n",
    "cv2.imshow(\"Merged\", merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Visualizar cada canal con su color\n",
    "zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision-env",
   "language": "python",
   "name": "computer-vision-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "616px",
   "left": "0px",
   "right": "20px",
   "top": "106px",
   "width": "213px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
