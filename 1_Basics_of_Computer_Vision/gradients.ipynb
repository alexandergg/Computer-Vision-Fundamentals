{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision – Gradients & Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos gradientes para detectar bordes en imágenes, lo que nos permite encontrar contornos y contornos de objetos en imágenes. Se utilizan como entradas para cuantificar imágenes a través de la extracción de características, de hecho, los descriptores de imagen altamente exitosos y conocidos, como el histograma de gradientes orientados(HOG) y SIFT, se basan en las representaciones de gradiente de imagen. \n",
    "\n",
    "Los gradientes se utilizan incluso para construir mapas de bordes y contornos, que resaltan los objetos de una imagen. Por lo tanto, utilizamos gradientes todo el tiempo en la visión por computadora y el procesamiento de imágenes.\n",
    "\n",
    "Como mencioné en la introducción, los gradientes de imagen se usan como bloques de construcción básicos en muchas aplicaciones de procesamiento de imágenes y visión por computadora. Sin embargo, la aplicación principal de los gradientes de imagen se encuentra dentro de la detección de bordes. \n",
    "\n",
    "Como sugiere su nombre, la detección de bordes es el proceso de encontrar bordes en una imagen, que revelará información estructural sobre los objetos en una imagen. Por lo tanto, los bordes podrían corresponder a:\n",
    "\n",
    "1. Límites de un objeto en una imagen.\n",
    "2. Límites de sombreado o condiciones de iluminación en una imagen.\n",
    "3. Límites de “partes” dentro de un objeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formalmente, un gradiente de imagen se define como un cambio direccional en la intensidad de la imagen. En la práctica, los gradientes de imagen se estiman utilizando kernels como lo hicimos con el blur(difuminado) y smooth(suavizado), pero esta vez estamos tratando de encontrar los componentes estructurales de la imagen. Nuestro objetivo aquí es encontrar el cambio de dirección hacia el píxel central marcado en rojo tanto en la dirección x como en la dirección y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **magnitud del gradiente** se utiliza para medir qué tan fuerte es el cambio en la intensidad de la imagen. La magnitud del gradiente es un número de valor real que cuantifica la \"fuerza\" del cambio en la intensidad. \n",
    "\n",
    "Mientras que la **orientación del gradiente** se usa para determinar en qué dirección apunta el cambio de intensidad. Como sugiere su nombre, la orientación del degradado nos dará un ángulo o que podemos usar para cuantificar la dirección del cambio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"C:/Users/algonzalez/source/repos/Computer_Vision/1_Basics_of_Computer_Vision/images/bricks.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gradient manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del los gradientes sobre los ejes X y Y respectivamente\n",
    "gX = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "gY = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "\n",
    "# Computar el gradiente de magnitud y orientación\n",
    "mag = np.sqrt((gX ** 2) + (gY ** 2))\n",
    "orientation = np.arctan2(gY, gX) * (180 / np.pi) % 180\n",
    "\n",
    "# Encuentrar todos los píxeles que están dentro de los límites de ángulo superior e inferior\n",
    "idxs = np.where(orientation >= 50.0, orientation, -1)\n",
    "idxs = np.where(orientation <= 80.0, idxs, -1)\n",
    "mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "mask[idxs > -1] = 255\n",
    "\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Kernels to calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del los gradientes sobre los ejes X y Y respectivamente\n",
    "gX = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=1, dy=0)\n",
    "gY = cv2.Sobel(gray, ddepth=cv2.CV_64F, dx=0, dy=1)\n",
    "\n",
    "# las imágenes `gX` y` gY` son ahora del tipo de datos de punto flotante,\n",
    "# por lo que debemos tener cuidado de convertirlos de nuevo a 8 bits sin convertir\n",
    "# una representación entera para que otras funciones de OpenCV puedan utilizarlas\n",
    "gX = cv2.convertScaleAbs(gX)\n",
    "gY = cv2.convertScaleAbs(gY)\n",
    "\n",
    "# Combina las representaciones sobel X e Y en una sola imagen\n",
    "sobelCombined = cv2.addWeighted(gX, 0.5, gY, 0.5, 0)\n",
    "\n",
    "cv2.imshow(\"Sobel X\", gX)\n",
    "cv2.imshow(\"Sobel Y\", gY)\n",
    "cv2.imshow(\"Sobel Combined\", sobelCombined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El borde o \"Edge\" se define como discontinuidades en la intensidad de los píxeles, o la aparición de una gran diferencia y cambio en los valores de los píxeles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sted Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un borde escalonado o \"Step Edge\" se forma cuando hay un cambio abrupto en la intensidad de píxel de un lado de la discontinuidad al otro. o que indica un cambio brusco en el valor de píxel. Estos tipos de bordes tienden a ser fáciles de detectar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Imagen1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ramp Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un borde de rampa o \"Ramp Edge\" es como un \"Step Edge\", solo que el cambio en la intensidad de píxeles no es instantáneo. En cambio, el cambio en el valor de píxel se produce una distancia corta, pero finita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Imagen2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roof Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un borde de cresta o \"Roof Edge\" es similar a la combinación de dos \"Ramps Edges\", uno golpeadose contra el otro. En el contexto de la detección de bordes, se produce un borde de cresta cuando la intensidad de la imagen cambia bruscamente, pero luego vuelve al valor inicial después de una corta distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Imagen3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia del \"Roof Edge\" donde hay una meseta corta y finita en la parte superior del borde, el borde del techo no tiene tal meseta. En su lugar, subimos lentamente a ambos lados del borde, pero la parte superior es un pináculo y simplemente volvemos a caer por la parte inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Imagen4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision-env",
   "language": "python",
   "name": "computer-vision-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "616px",
   "left": "0px",
   "right": "20px",
   "top": "106px",
   "width": "213px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
